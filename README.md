---

# ğŸ§  H.A.AI.E â€” Help Against Anxiety (Experimental)

### Local Emotional Companion â€” Private â€¢ Lightweight â€¢ Humanized

---

## ğŸŒ± Overview

**H.A.AI.E** is an experimental AI companion designed to help people overcome social anxiety and loneliness â€” locally, without internet access, and without monetizing personal data.

Itâ€™s *not* meant to replace human interaction, but to help users **relearn communication and emotional expression** in a safe, private, and non-commercial way.

---

## ğŸ¯ Goals

* ğŸ—£ï¸ **Conversational companion**: Interact naturally with emotion-based feedback.
* ğŸ”’ **Privacy first**: Everything runs **locally** (no cloud, no data collection).
* ğŸ§â€â™€ï¸ **Humanized interface**: Live2D-based Vtuber for visual expression.
* ğŸ§© **Lightweight and accessible**: Optimized for low-resource systems.
* ğŸ§˜â€â™‚ï¸ **Emotional support**: Non-judgmental presence to help practice communication.

---

## âš™ï¸ Current Development Status

âœ… Facial and expression reactions based on text
âš™ï¸ Live2D model integrated
âŒ No voice or LLM integration yet
ğŸš§ `main.py` is the current entry point for testing

---

## ğŸ§© Model Dependencies

To run **H.A.AI.E**, youâ€™ll need to download or clone the following models:

### ğŸ—£ï¸ Text-to-Speech

```
OuteTTS-0.2-500M
```

### ğŸ’¬ Emotion Detection

```
ModernBERT-large-go-emotions
multilingual_go_emotions_V1.2
```

### ğŸ˜ Sarcasm & Irony Detection

```
sarcasm-detection-RoBERTa-base-CR
twitter-roberta-base-irony
```

### ğŸ§â€â™€ï¸ Speech Model (French Example)

```
fr/fr_FR/upmc/medium/fr_FR-upmc-medium.onnx
fr/fr_FR/upmc/medium/fr_FR-upmc-medium.onnx.json
```

These include:

* `MODEL_CARD`
* Example voice samples (`speaker_0.mp3`, `speaker_1.mp3`)

---

## ğŸ§° Installation & Run

### 1. Clone the repository

```bash
git clone https://github.com/yourusername/HAAIE.git
cd HAAIE
```

### 2. Create a virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the test script

```bash
python test.py
```

---

## ğŸ§  Architecture Summary

**Pipeline:**

1. User input â†’ Emotion detection
2. Emotion classification â†’ Expression control
3. Live2D animation â†’ Visual feedback
4. (Planned) Speech-to-text + LLM â†’ Intelligent reply
5. (Planned) TTS â†’ Voice output
---

## ğŸš€ Roadmap

| Feature            | Status         | Notes                             |
| ------------------ | -------------- | --------------------------------- |
| Expression mapping | âœ… Done        | Based on sentence analysis        |
| Live2D integration | âœ… Done        | Animated avatar                   |
| Voice output       | âœ… Done        | Local TTS via Piper               |
| Offline LLM        | ğŸ”œ Planned     | Compact conversational model      |
| Emotion dataset    | ğŸ§© In progress | Based on Reddit/Discord data      |
| Code optimization  | ğŸš§ Planned     | Improve modularity and efficiency |

---

## ğŸ’¡ Philosophy

> â€œYour loneliness is not a product.â€

H.A.AI.E is open-source and built for **mental health awareness**, **privacy**, and **social reconnection**, not profit.

---

## ğŸ§‘â€ğŸ’» Author

Independent developer â€” France
Contact: perso[aroba]archibarbu[dot]com

---

#### Please check license before use it in commercial project.