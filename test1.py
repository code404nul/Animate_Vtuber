import whisper
import torch
from time import time

# V√©rifie si CUDA est dispo
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"‚úÖ Appareil utilis√© : {device}")

# Charge le mod√®le sur le bon appareil
model = whisper.load_model("medium", device=device)

start = time()
result = model.transcribe("output.wav")
end = time()

print("\nüó£Ô∏è Transcription :")
print(result["text"])
print(f"\n‚è±Ô∏è Temps de transcription : {end - start:.2f} secondes")
