import whisper
import sounddevice as sd
import numpy as np
from time import time
import threading
from queue import Queue, Empty
from utils.config_manager import size_stt, device
import torch

# Configuration globale
model = None
model_lock = threading.Lock()
SAMPLE_RATE = 16000

def load_model():
    """Charge le mod√®le Whisper une seule fois (thread-safe) avec support GPU"""
    global model
    with model_lock:
        if model is None:
            device_name = device()  # Appeler device() ici pour obtenir la cha√Æne
            print(f"üîÑ Chargement du mod√®le Whisper sur {device_name}...")
            
            if device_name == "gpu":
                model = whisper.load_model(size_stt(), device="cuda")
                print(f"‚úì Mod√®le charg√© sur GPU (CUDA) - {torch.cuda.get_device_name(0)}")
            else:
                model = whisper.load_model(size_stt(), device="cpu")
                print("‚úì Mod√®le charg√© sur CPU")
    
    return model

def detect_voice_activity(audio, threshold=0.01, min_speech_duration=0.5):
    """
    D√©tecte si l'audio contient de la parole (VAD simple)
    Args:
        audio: signal audio
        threshold: seuil d'√©nergie pour d√©tecter la parole
        min_speech_duration: dur√©e minimale de parole (en secondes)
    Returns:
        bool: True si de la parole est d√©tect√©e
    """
    # Calculer l'√©nergie RMS par fen√™tre
    window_size = int(SAMPLE_RATE * 0.1)  # Fen√™tres de 100ms
    energy = np.array([
        np.sqrt(np.mean(audio[i:i+window_size]**2))
        for i in range(0, len(audio) - window_size, window_size)
    ])
    
    # Compter les fen√™tres avec √©nergie significative
    speech_windows = np.sum(energy > threshold)
    speech_duration = speech_windows * 0.1
    
    return speech_duration >= min_speech_duration

def record_audio(duration=30, sample_rate=SAMPLE_RATE):
    """
    Enregistre l'audio depuis le microphone
    Args:
        duration: dur√©e d'enregistrement en secondes
        sample_rate: fr√©quence d'√©chantillonnage (16kHz recommand√© pour Whisper)
    """
    print(f"üé§ Enregistrement en cours ({duration}s)...")
    
    # Pr√©-allocation du buffer pour √©viter les r√©allocations
    audio = sd.rec(
        int(duration * sample_rate), 
        samplerate=sample_rate, 
        channels=1, 
        dtype='float32',
        blocking=True
    )
    
    print("‚úì Enregistrement termin√©")
    return audio.flatten()

def recording_worker(audio_queue, duration, stop_event):
    """
    Thread worker pour l'enregistrement continu
    Args:
        audio_queue: file d'attente pour stocker les audios enregistr√©s
        duration: dur√©e de chaque enregistrement
        stop_event: √©v√©nement pour arr√™ter le thread proprement
    """
    while not stop_event.is_set():
        try:
            audio = record_audio(duration=duration)
            
            # V√©rifier si l'audio contient de la parole
            if detect_voice_activity(audio):
                print("‚úì Parole d√©tect√©e, ajout √† la queue de transcription")
                audio_queue.put(audio)
            else:
                print("‚äò Silence d√©tect√©, transcription ignor√©e")
                
        except Exception as e:
            print(f"‚ùå Erreur lors de l'enregistrement : {e}")
            if not stop_event.is_set():
                continue

def transcription_worker(audio_queue, stop_event):
    """
    Thread worker pour la transcription avec optimisations GPU
    Args:
        audio_queue: file d'attente contenant les audios √† transcrire
        stop_event: √©v√©nement pour arr√™ter le thread proprement
    """
    mdl = load_model()
    device_name = device()  # Obtenir le nom du device
    
    # Options de transcription optimis√©es
    transcribe_options = {
        "fp16": device_name == "gpu",
        "language": "fr",  # Sp√©cifier la langue pour acc√©l√©rer
        "beam_size": 5,  # R√©duire pour plus de vitesse (d√©faut: 5)
        "best_of": 5,  # R√©duire pour plus de vitesse (d√©faut: 5)
        "temperature": 0.0,  # D√©sactiver le sampling pour plus de vitesse
    }
    
    print(f"üîß Options de transcription: fp16={transcribe_options['fp16']}")
    
    while not stop_event.is_set() or not audio_queue.empty():
        try:
            # Attendre un audio avec timeout
            audio = audio_queue.get(timeout=1)
            
            print("üîÑ Transcription en cours...")
            start = time()
            
            # Transcription avec options optimis√©es
            result = mdl.transcribe(audio, **transcribe_options)
            
            end = time()
            
            print(f"‚è±Ô∏è  Temps de transcription : {end - start:.2f} secondes")
            print(f"üìù Transcription : {result['text']}\n")
            
            # Nettoyer la m√©moire GPU si utilis√©e
            if device_name == "gpu":
                torch.cuda.empty_cache()
            
            audio_queue.task_done()
            
        except Empty:
            continue
        except Exception as e:
            print(f"‚ùå Erreur pendant la transcription : {e}")
            if not audio_queue.empty():
                audio_queue.task_done()

def transcription_loop(interval=30):
    """
    Boucle de transcription continue avec enregistrement et analyse en parall√®le
    Args:
        interval: dur√©e d'enregistrement (en secondes)
    """
    # Queue avec taille limit√©e pour √©viter l'accumulation
    audio_queue = Queue(maxsize=2)
    stop_event = threading.Event()
    
    # Cr√©er les threads
    recorder_thread = threading.Thread(
        target=recording_worker,
        args=(audio_queue, interval, stop_event),
        daemon=True,
        name="AudioRecorder"
    )
    transcriber_thread = threading.Thread(
        target=transcription_worker,
        args=(audio_queue, stop_event),
        daemon=True,
        name="AudioTranscriber"
    )
    
    print("üöÄ D√©marrage de la transcription continue...")
    print(f"   Device: {device()}")
    print("   (Appuyez sur Ctrl+C pour arr√™ter)\n")
    
    # D√©marrer les threads
    recorder_thread.start()
    transcriber_thread.start()
    
    try:
        # Attendre ind√©finiment
        while recorder_thread.is_alive() or transcriber_thread.is_alive():
            recorder_thread.join(timeout=1)
            transcriber_thread.join(timeout=1)
            
    except KeyboardInterrupt:
        print("\nüõë Arr√™t de la transcription...")
        stop_event.set()
        
        # Attendre que les threads se terminent
        recorder_thread.join(timeout=5)
        transcriber_thread.join(timeout=10)
        
        # Nettoyer la m√©moire GPU
        if device() == "gpu":
            torch.cuda.empty_cache()
        
        print("‚úì Arr√™t termin√©")

def transcribe_audio(duration=30):
    """
    Enregistre et transcrit l'audio du microphone (mode simple, non-continu)
    Args:
        duration: dur√©e d'enregistrement en secondes
    """
    # Enregistrer depuis le micro
    audio = record_audio(duration=duration)
    
    # V√©rifier la pr√©sence de parole
    if not detect_voice_activity(audio):
        print("‚äò Aucune parole d√©tect√©e dans l'enregistrement")
        return ""
    
    # Charger le mod√®le
    mdl = load_model()
    device_name = device()  # Obtenir le nom du device
    
    # Options optimis√©es
    transcribe_options = {
        "fp16": device_name == "gpu",
        "language": "fr",
        "beam_size": 5,
        "best_of": 5,
        "temperature": 0.0,
    }
    
    # Transcrire
    start = time()
    result = mdl.transcribe(audio, **transcribe_options)
    end = time()
    
    print(f"‚è±Ô∏è  Temps de transcription : {end - start:.2f} secondes")
    print(f"üìù Transcription : {result['text']}\n")
    
    if device_name == "gpu":
        torch.cuda.empty_cache()
    
    return result["text"]

if __name__ == "__main__":
    # Mode continu avec enregistrement et transcription en parall√®le
    transcription_loop(interval=30)